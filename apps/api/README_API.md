# OCR Platform ‚Äì API

FastAPI app: t·∫°o job OCR, upload file, xem tr·∫°ng th√°i. C·∫ßn PostgreSQL, Redis, MinIO (S3).

---

## Ch·∫°y (Run)

### 1. B·∫±ng Docker (khuy·∫øn ngh·ªã)

T·ª´ **th∆∞ m·ª•c g·ªëc** repo (c√≥ `infra/docker-compose.yml`):

```bash
docker compose -f infra/docker-compose.yml up --build
```

Service `api` ch·∫°y t·∫°i **http://localhost:8000**. C·∫ßn c√≥ Redis, Postgres, MinIO (ƒë√£ b·ªè MinIO trong compose; c·∫•u h√¨nh qua `infra/.env`).

### 2. Ch·∫°y local (uv)

**Y√™u c·∫ßu:** Python 3.11+, [uv](https://docs.astral.sh/uv/), Postgres + Redis + MinIO ƒëang ch·∫°y.

```bash
# C√†i uv (n·∫øu ch∆∞a): curl -LsSf https://astral.sh/uv/install.sh | sh
# T·ª´ th∆∞ m·ª•c g·ªëc repo
cd apps/api
uv sync
```

ƒê·∫∑t bi·∫øn m√¥i tr∆∞·ªùng (ho·∫∑c t·∫°o file `.env` trong `apps/api`):

```bash
export DATABASE_URL="postgresql+psycopg://ocr:ocr@localhost:5432/ocr"
export CELERY_BROKER_URL="redis://localhost:6379/0"
export CELERY_RESULT_BACKEND="redis://localhost:6379/1"
export S3_ENDPOINT="http://localhost:9000"   # ho·∫∑c MINIO_ENDPOINT=host:port
export S3_ACCESS_KEY="minio"
export S3_SECRET_KEY="minio123"
export S3_BUCKET="ocr"
```

Ch·∫°y server:

```bash
uv run uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

API: **http://localhost:8000**. Docs: http://localhost:8000/docs .

---

## Test

### Health

```bash
curl http://localhost:8000/health
# ‚Üí {"ok":true}
```

### T·∫°o job

```bash
curl -X POST http://localhost:8000/v1/ocr/jobs -H "X-Tenant-Id: demo"
# ‚Üí {"job_id":"...","status":"PENDING_UPLOAD"}
```

### Upload file (thay `<JOB_ID>`)

```bash
curl -X POST "http://localhost:8000/v1/ocr/jobs/<JOB_ID>/upload" \
  -H "X-Tenant-Id: demo" \
  -F "file=@/path/to/image.jpg"
```

### Xem tr·∫°ng th√°i job

```bash
curl http://localhost:8000/v1/ocr/jobs/<JOB_ID> -H "X-Tenant-Id: demo"
```

### Lu·ªìng Detect ‚Üí ch·ªânh s·ª≠a ‚Üí OCR

- Sau upload, worker ch·∫°y **Detect** (CRAFT), l∆∞u k·∫øt qu·∫£ v√†o DB (`detect_result`) v√† MinIO; status = `DETECT_DONE`.
- **GET** `/v1/ocr/jobs/<JOB_ID>` tr·∫£ v·ªÅ `detect_result` (JSON). **GET** `/v1/ocr/jobs/<JOB_ID>/detect` tr·∫£ v·ªÅ c√πng n·ªôi dung (∆∞u ti√™n DB).
- **PATCH** `/v1/ocr/jobs/<JOB_ID>/detect` ‚Äî body JSON `{ "job_id", "pages": [ { "page_index", "width", "height", "boxes": [...] } ] }` ‚Äî c·∫≠p nh·∫≠t `detect_result` trong DB (ch·ªânh s·ª≠a boxes tr∆∞·ªõc khi OCR).
- **POST** `/v1/ocr/jobs/<JOB_ID>/run-ocr` ‚Äî g·ª≠i task `ocr.run_ocr_job` (ch·∫°y Recognize d√πng `detect_result` trong DB), sau khi ch·ªânh s·ª≠a xong.

### Unit test (khi ƒë√£ th√™m pytest)

```bash
cd apps/api
uv run pytest tests/ -v
```

(Hi·ªán t·∫°i `tests/` c√≥ th·ªÉ tr·ªëng; th√™m test r·ªìi d√πng l·ªánh tr√™n.)

### Migration DB: c·ªôt `detect_result`

N·∫øu b·∫£ng `ocr_jobs` ƒë√£ t·ªìn t·∫°i, ch·∫°y migration m·ªôt l·∫ßn:

```bash
psql "$DATABASE_URL" -f infra/migrations/add_ocr_jobs_detect_result.sql
```

Ho·∫∑c v·ªõi SQLAlchemy `create_all`, ƒë·∫£m b·∫£o model ƒë√£ c√≥ c·ªôt `detect_result` r·ªìi t·∫°o b·∫£ng m·ªõi / th√™m c·ªôt th·ªß c√¥ng.

### Lint & type check (Ruff + Pyright)

```bash
cd apps/api
uv add --dev ruff pyright
uv run ruff check app
uv run ruff format app
uv run pyright app
```

---

## Docker

### Build image API (t·ª´ th∆∞ m·ª•c g·ªëc repo)

Context ph·∫£i l√† repo root (ƒë·ªÉ copy `libs/ocr_core`):

```bash
docker build -f apps/api/Dockerfile -t ocr-api:local .
```

### Ch·∫°y container (v√≠ d·ª•)

```bash
docker run --rm -p 8000:8000 \
  -e DATABASE_URL="postgresql+psycopg://ocr:ocr@host.docker.internal:5432/ocr" \
  -e CELERY_BROKER_URL="redis://host.docker.internal:6379/0" \
  -e CELERY_RESULT_BACKEND="redis://host.docker.internal:6379/1" \
  -e S3_ENDPOINT="http://host.docker.internal:9000" \
  -e S3_ACCESS_KEY="minio" \
  -e S3_SECRET_KEY="minio123" \
  -e S3_BUCKET="ocr" \
  ocr-api:local
```

### D√πng docker-compose (c·∫£ stack)

T·ª´ th∆∞ m·ª•c g·ªëc:

```bash
docker compose -f infra/docker-compose.yml up -d
```

API: http://localhost:8000. Bi·∫øn m√¥i tr∆∞·ªùng l·∫•y t·ª´ `infra/.env` (xem `infra/.env.example`).

---

## Bi·∫øn m√¥i tr∆∞·ªùng

| Bi·∫øn | M√¥ t·∫£ |
|------|--------|
| `DATABASE_URL` | PostgreSQL (vd: `postgresql+psycopg://user:pass@host:5432/db`) |
| `CELERY_BROKER_URL` | Redis broker (vd: `redis://localhost:6379/0`) |
| `CELERY_RESULT_BACKEND` | Redis backend (vd: `redis://localhost:6379/1`) |
| `S3_ENDPOINT` | MinIO/S3 endpoint (vd: `http://localhost:9000`) |
| `S3_ACCESS_KEY` / `S3_SECRET_KEY` | Credentials S3/MinIO |
| `S3_BUCKET` | Bucket (m·∫∑c ƒë·ªãnh: `ocr`) |
| `MINIO_ENDPOINT` / `MINIO_ACCESS_KEY` / `MINIO_SECRET_KEY` / `MINIO_SECURE` | D√πng thay `S3_*` n·∫øu c·∫ßn |

## T√≥m t·∫Øt ki·∫øn tr√∫c logic

    Client
      ‚Üì
    FastAPI
      ‚îú‚îÄ‚îÄ Postgres (metadata)
      ‚îú‚îÄ‚îÄ MinIO (file storage)
      ‚îî‚îÄ‚îÄ Redis ‚Üí Celery
                  ‚Üì
              Worker
                  ‚Üì
              OCR Core
                  ‚Üì
              MinIO result
                  ‚Üì
              Update DB
üìå B∆∞·ªõc 1 ‚Äì L∆∞u file v√†o MinIO --> File ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o object storage (MinIO).
üìå B∆∞·ªõc 2 ‚Äì Update DB  -->  L∆∞u metadata v√†o Postgres.
üìå B∆∞·ªõc 3 ‚Äì G·ªåI REDIS (th√¥ng qua Celery)  
    ƒê√¢y l√† ƒëo·∫°n quan tr·ªçng:
      from app.core.deps import celery_app
      celery_app.send_task("ocr.run_job", args=[job_id])
    ‚ö† Ch√≠nh d√≤ng n√†y s·∫Ω g·ª≠i message v√†o Redis.
    Redis ch·ªâ d√πng l√†m: Message Queue trung gian gi·ªØa API v√† Worker
    Redis ho·∫°t ƒë·ªông  Khi d√≤ng n√†y ch·∫°y: celery_app.send_task("ocr.run_job", args=[job_id])
4Ô∏è‚É£ Worker nh·∫≠n task t·ª´ Redis (apps/worker/app/tasks/ocr_tasks.py)
5Ô∏è‚É£ Vai tr√≤ th·ª±c s·ª± c·ªßa Redis trong project n√†y
    üîπ 1. Message Broker: Gi√∫p API kh√¥ng ph·∫£i ch·ªù OCR x·ª≠ l√Ω. 
           - N·∫øu kh√¥ng c√≥ Redis: API ‚Üí ch·∫°y OCR tr·ª±c ti·∫øp ‚Üí block request 10‚Äì30s
           - C√≥ Redis: API ‚Üí g·ª≠i message ‚Üí tr·∫£ 200 ngay Worker x·ª≠ l√Ω n·ªÅn
    üîπ 2. Buffer ch·ªëng qu√° t·∫£i: ‚Üí Gi√∫p h·ªá th·ªëng kh√¥ng s·∫≠p.
           - N·∫øu 1000 user upload c√πng l√∫c: 
             + API v·∫´n nh·∫≠n b√¨nh th∆∞·ªùng
             + Redis x·∫øp h√†ng queue
             + Worker x·ª≠ l√Ω d·∫ßn
    üîπ 3. T√°ch bi·ªát service: Ch·ªâ c·∫ßn push message v√†o Redis.
          - API kh√¥ng c·∫ßn bi·∫øt:
          + Worker ƒëang ch·∫°y ·ªü ƒë√¢u
          + C√≥ bao nhi√™u worker
6Ô∏è‚É£ T·∫°i sao kh√¥ng g·ªçi tr·ª±c ti·∫øp worker?
    N·∫øu l√†m v·∫≠y:
              + API s·∫Ω b·ªã block
              + Kh√¥ng scale ƒë∆∞·ª£c
              + Kh√¥ng retry ƒë∆∞·ª£c
              + Kh√¥ng c√≥ queue

    
7Ô∏è‚É£ T·ªïng flow ƒë·∫ßy ƒë·ªß c√≥ Redis:
            Client
              ‚Üì
            FastAPI
              ‚Üì
            Save file ‚Üí MinIO
            Update DB ‚Üí Postgres
              ‚Üì
            Send task ‚Üí Redis
              ‚Üì
            Worker l·∫•y task t·ª´ Redis
              ‚Üì
            OCR x·ª≠ l√Ω
              ‚Üì
            Save result ‚Üí MinIO
            Update DB ‚Üí DONE
  üîü T√≥m l·∫°i
        ƒêo·∫°n call Redis:
        celery_app.send_task("ocr.run_job", args=[job_id])
        Vai tr√≤ Redis:
        ‚úÖ L√†m message queue
        ‚úÖ T√°ch API v√† Worker
        ‚úÖ Gi√∫p x·ª≠ l√Ω async
        ‚úÖ Gi√∫p scale system
        ‚ùå Kh√¥ng l∆∞u file
        ‚ùå Kh√¥ng l∆∞u metadata


## Celery l√† m·ªôt distributed task queue (h·ªá th·ªëng x·ª≠ l√Ω t√°c v·ª• b·∫•t ƒë·ªìng b·ªô ph√¢n t√°n) cho Python.:
Celery gi√∫p b·∫°n ch·∫°y c√°c c√¥ng vi·ªác n·∫∑ng (OCR, g·ª≠i email, x·ª≠ l√Ω ·∫£nh, AI‚Ä¶) ·ªü background thay v√¨ ch·∫°y tr·ª±c ti·∫øp trong API.
1Ô∏è‚É£ V·∫•n ƒë·ªÅ n·∫øu KH√îNG c√≥ Celery
    Gi·∫£ s·ª≠ API upload xong ch·∫°y OCR ngay:
      run_ocr(file)
      return result
    N·∫øu OCR m·∫•t 15‚Äì30 gi√¢y:
      ‚ùå API b·ªã block
      ‚ùå User ph·∫£i ch·ªù
      ‚ùå Server d·ªÖ qu√° t·∫£i
      ‚ùå Kh√¥ng scale t·ªët
2Ô∏è‚É£ Celery gi·∫£i quy·∫øt nh∆∞ th·∫ø n√†o?
    Celery t√°ch h·ªá th·ªëng th√†nh 2 ph·∫ßn: 
    API (Producer)  ‚Üí  Queue (Redis)  ‚Üí  Worker (Consumer)
    Flow:
      API nh·∫≠n request
      API g·ª≠i task v√†o queue
      Tr·∫£ response ngay
      Worker x·ª≠ l√Ω task ·ªü background
3Ô∏è‚É£ Celery g·ªìm nh·ªØng th√†nh ph·∫ßn g√¨?
    üîπ 1. Producer (API) : celery_app.send_task("ocr.run_job", args=[job_id])
    üîπ 2. Broker (Redis ho·∫∑c RabbitMQ): Celery kh√¥ng t·ª± l∆∞u task ‚Äî n√≥ d√πng broker.
    üîπ 3. Worker: celery -A app worker -l info
        Worker:
          L·∫Øng nghe Redis
          Khi c√≥ task ‚Üí l·∫•y xu·ªëng
          Th·ª±c thi function
          @shared_task(name="ocr.run_job")
          def run_job(job_id):
              ...
4Ô∏è‚É£ Celery ho·∫°t ƒë·ªông n·ªôi b·ªô ra sao?
    send_task("ocr.run_job", args=[job_id])
  
  Celery s·∫Ω:
        Serialize task th√†nh JSON
        ƒê·∫©y v√†o Redis queue
        Worker polling Redis
        Worker l·∫•y task
        Deserialize
        Ch·∫°y function
  5Ô∏è‚É£ Celery d√πng ƒë·ªÉ l√†m g√¨ trong th·ª±c t·∫ø?
      R·∫•t ph·ªï bi·∫øn trong production:
            Use case	V√≠ d·ª•
            OCR	X·ª≠ l√Ω file
            AI inference	Ch·∫°y model
            Email	G·ª≠i email async
            SMS	G·ª≠i SMS
            Video processing	Encode video
            Data pipeline	ETLZ
  8Ô∏è‚É£ Trong project OCR c·ªßa b·∫°n
        FastAPI ‚Üí g·ª≠i task ‚Üí Redis 
        Worker ‚Üí nh·∫≠n task ‚Üí ch·∫°y OCR

M·ªôt h·ªá th·ªëng gi√∫p ch·∫°y c√°c c√¥ng vi·ªác n·∫∑ng ·ªü background, th√¥ng qua queue (Redis/RabbitMQ), t√°ch bi·ªát API v√† Worker.
    cd /mnt/data/code/ocr-platform/apps/worker
    uv run celery -A app.worker:celery_app worker -l info